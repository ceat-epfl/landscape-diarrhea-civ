{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import momepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylandstats as pls\n",
    "import rasterio\n",
    "from rasterio import mask\n",
    "from rasterstats import zonal_stats\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = \"data/output/\"\n",
    "dest_temp_dir = \"data/temp/pylandstats/\"\n",
    "input_dir = \"data/temp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landscape metrics: Raster zonal stats for buffer areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set reference polygon layer (buffer areas) for zonal statistics\n",
    "aggr_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pylandstats (lancover patch morphology) in buffer areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragmenting raster...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7435699abad6463a8719ae9d08a5dd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster fragmented\n",
      "calculating landscape metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d397b4a8dc9f4a138a94838bb880859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landscape metrics calculated\n",
      "joining and saving temp gdf...\n",
      "joined\n",
      "temp gdf saved\n",
      "removing temp .tifs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8326a5bb30dd4cd1a80a84389598b49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp .tifs removed\n"
     ]
    }
   ],
   "source": [
    "# ANALYZE LAND COVER CLASSES WITH PYLANDSTATS\n",
    "\n",
    "# Input raster (with 16 built-up classes)\n",
    "\n",
    "input_rasterpath = path.join(\n",
    "    input_dir, \"ESACCI-LC-L4-LCCS-Map-300m-P1Y-2012-v2.0.7_rclass16.tif\"\n",
    ")\n",
    "\n",
    "# Fragment raster into pixel units (for faster calculus with pylandstats)\n",
    "\n",
    "print(\"fragmenting raster...\")\n",
    "temp_filepaths = []\n",
    "\n",
    "with rasterio.open(input_rasterpath) as src:\n",
    "    meta = src.meta.copy()\n",
    "    for un_identifier, geom in tqdm(\n",
    "        zip(aggr_poly_gdf[\"v001\"], aggr_poly_gdf[\"geometry\"]),\n",
    "        total=aggr_poly_gdf.shape[0],\n",
    "    ):\n",
    "        out_image, out_transform = mask.mask(\n",
    "            src, [geom], crop=True\n",
    "        )  # returns array with band values\n",
    "        meta.update(\n",
    "            {\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "            }\n",
    "        )\n",
    "        temp_filepath = path.join(dest_temp_dir, str(un_identifier) + \".tif\")\n",
    "        with rasterio.open(temp_filepath, \"w\", **meta) as dst:\n",
    "            dst.write(out_image[0], 1)\n",
    "        temp_filepaths.append(temp_filepath)\n",
    "\n",
    "print(\"raster fragmented\")\n",
    "\n",
    "# Calculate landscape metrics with pylandstats:\n",
    "\n",
    "# Create empty dataframe (columns = all raster classes)\n",
    "print(\"calculating landscape metrics...\")\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for filepath in tqdm(temp_filepaths):\n",
    "    ls = pls.Landscape(filepath)\n",
    "    class_metrics_df = ls.compute_class_metrics_df(\n",
    "        metrics=[\"proportion_of_landscape\", \"edge_density\", \"fractal_dimension_am\"]\n",
    "    )\n",
    "    df = df.append(class_metrics_df.stack(), ignore_index=True)\n",
    "df = df.fillna(0)\n",
    "df = df.rename(columns=lambda col: col[1][:4] + \"_\" + str(col[0]))\n",
    "print(\"landscape metrics calculated\")\n",
    "\n",
    "# Remove attributes resulting of erroneous built-up raster class ('190')\n",
    "df_col_list50 = list(df.columns[df.columns.str.endswith(\"_190\")])\n",
    "df_c = df.drop(columns=df_col_list50)\n",
    "\n",
    "# Join dataframe to geodataframe\n",
    "print(\"joining and saving temp gdf...\")\n",
    "gdf_final = pd.concat([aggr_poly_gdf, df_c], axis=1)\n",
    "print(\"joined\")\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_1.shp\"))\n",
    "print(\"temp gdf saved\")\n",
    "\n",
    "# remove temp .tif files:\n",
    "print(\"removing temp .tifs...\")\n",
    "for filepath in tqdm(temp_filepaths):\n",
    "    os.remove(filepath)\n",
    "print(\"temp .tifs removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes in raster: 34\n",
      "list of classes in raster [    0    10    11    20    30    40    50    60    62   100   110   120\n",
      "   122   130   160   170   180   190   210 19011 19012 19013 19014 19021\n",
      " 19022 19023 19024 19031 19032 19033 19034 19042 19043 19044]\n",
      "number of columns in df: 99\n",
      "n° columns in df OK\n",
      "list of cols in df: ['prop_10', 'edge_10', 'frac_10', 'prop_30', 'edge_30', 'frac_30', 'prop_50', 'edge_50', 'frac_50', 'prop_19021', 'edge_19021', 'frac_19021', 'prop_19022', 'edge_19022', 'frac_19022', 'edge_11', 'frac_11', 'prop_11', 'edge_40', 'frac_40', 'prop_40', 'edge_62', 'frac_62', 'prop_62', 'edge_100', 'frac_100', 'prop_100', 'edge_120', 'frac_120', 'prop_120', 'edge_19033', 'frac_19033', 'prop_19033', 'edge_19034', 'frac_19034', 'prop_19034', 'edge_19011', 'frac_19011', 'prop_19011', 'edge_122', 'frac_122', 'prop_122', 'edge_19032', 'frac_19032', 'prop_19032', 'edge_19012', 'frac_19012', 'prop_19012', 'edge_160', 'frac_160', 'prop_160', 'edge_210', 'frac_210', 'prop_210', 'edge_60', 'frac_60', 'prop_60', 'edge_170', 'frac_170', 'prop_170', 'edge_19042', 'frac_19042', 'prop_19042', 'edge_19043', 'frac_19043', 'prop_19043', 'edge_19044', 'frac_19044', 'prop_19044', 'edge_19023', 'frac_19023', 'prop_19023', 'edge_19013', 'frac_19013', 'prop_19013', 'edge_180', 'frac_180', 'prop_180', 'edge_20', 'frac_20', 'prop_20', 'edge_19014', 'frac_19014', 'prop_19014', 'edge_19024', 'frac_19024', 'prop_19024', 'edge_190', 'frac_190', 'prop_190', 'edge_130', 'frac_130', 'prop_130', 'edge_19031', 'frac_19031', 'prop_19031', 'edge_110', 'frac_110', 'prop_110']\n",
      "columns dropped (class 190): ['edge_190', 'frac_190', 'prop_190']\n",
      "aggr_poly_gdf columns: 2\n",
      "df_c columns (to join): 96\n",
      "gdf_final columns: 98\n",
      "{'driver': 'GTiff', 'dtype': 'int32', 'nodata': 0.0, 'width': 2198, 'height': 2295, 'count': 1, 'crs': CRS.from_epsg(4326), 'transform': Affine(0.0027777777777780025, 0.0, -8.599999999986286,\n",
      "       0.0, -0.002777777777778, 10.736111111104782)}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Check results\n",
    "\n",
    "with rasterio.open(input_rasterpath) as src:\n",
    "    src_array = src.read(1)\n",
    "print(\"number of classes in raster:\", len(np.unique(src_array)))\n",
    "print(\"list of classes in raster\", np.unique(src_array))\n",
    "print(\"number of columns in df:\", len(df.columns.to_list()))\n",
    "if (len(df.columns.to_list())) != ((len(np.unique(src_array)) - 1) * 3):\n",
    "    print(\n",
    "        \"error: check n° columns in df, should be:\", (len(np.unique(src_array)) - 1) * 3\n",
    "    )\n",
    "else:\n",
    "    print(\"n° columns in df OK\")\n",
    "print(\"list of cols in df:\", df.columns.to_list())\n",
    "print(\"columns dropped (class 190):\", df_col_list50)\n",
    "print(\"aggr_poly_gdf columns:\", aggr_poly_gdf.shape[1])\n",
    "print(\"df_c columns (to join):\", df_c.shape[1])\n",
    "print(\"gdf_final columns:\", gdf_final.shape[1])\n",
    "print(src.meta)\n",
    "\n",
    "# Count pixels with band value = '190'\n",
    "# >> these pixels are those with a missing value either for density or illumination\n",
    "# >> therefore have not been reclassified (so kept band value of '190')\n",
    "# >> The number should be 4 (see notebook 1, preprocessing)\n",
    "print(\n",
    "    np.unique(src_array, return_counts=True)[1][list(np.unique(src_array)).index(190)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragmenting raster...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3769614352a497f8854acf97e4697fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster fragmented\n",
      "calculating landscape metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1296ef3cbfe40a29c1c0cac6055371c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landscape metrics calculated\n",
      "joining and saving temp gdf...\n",
      "joined\n",
      "temp gdf saved\n",
      "removing temp .tifs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a83c89c450d40a1993b28bdb83d0898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp .tifs removed\n"
     ]
    }
   ],
   "source": [
    "# New round of pylandstats with simplified land cover (non-categorized built up class)\n",
    "\n",
    "# Input raster (single built-up class, '190')\n",
    "\n",
    "input_rasterpath = path.join(\n",
    "    input_dir, \"ESACCI-LC-L4-LCCS-Map-300m-P1Y-2012-v2.0.7.tif\"\n",
    ")\n",
    "\n",
    "# Fragment raster into pixel units (for faster calculus with pylandstats)\n",
    "\n",
    "print(\"fragmenting raster...\")\n",
    "temp_filepaths = []\n",
    "\n",
    "with rasterio.open(input_rasterpath) as src:\n",
    "    meta = src.meta.copy()\n",
    "    for un_identifier, geom in tqdm(\n",
    "        zip(aggr_poly_gdf[\"v001\"], aggr_poly_gdf[\"geometry\"]),\n",
    "        total=aggr_poly_gdf.shape[0],\n",
    "    ):\n",
    "        out_image, out_transform = mask.mask(\n",
    "            src, [geom], crop=True\n",
    "        )  # returns array with band values\n",
    "        meta.update(\n",
    "            {\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "                \"dtype\": \"int32\",\n",
    "            }\n",
    "        )\n",
    "        temp_filepath = path.join(dest_temp_dir, str(un_identifier) + \".tif\")\n",
    "        with rasterio.open(temp_filepath, \"w\", **meta) as dst:\n",
    "            dst.write(out_image[0].astype(np.int32), 1)\n",
    "        temp_filepaths.append(temp_filepath)\n",
    "\n",
    "print(\"raster fragmented\")\n",
    "\n",
    "# Calculate landscape metrics with pylandstats:\n",
    "\n",
    "# Create empty dataframe (columns = all raster classes)\n",
    "print(\"calculating landscape metrics...\")\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for filepath in tqdm(temp_filepaths):\n",
    "    ls = pls.Landscape(filepath)\n",
    "    class_metrics_df = ls.compute_class_metrics_df(\n",
    "        metrics=[\"proportion_of_landscape\", \"edge_density\", \"fractal_dimension_am\"]\n",
    "    )\n",
    "    df = df.append(class_metrics_df.stack(), ignore_index=True)\n",
    "df = df.fillna(0)\n",
    "df = df.rename(columns=lambda col: col[1][:4] + \"_\" + str(col[0]))\n",
    "print(\"landscape metrics calculated\")\n",
    "\n",
    "# Add attributes to geodataframe (join tables of attributes)\n",
    "\n",
    "# Get temp gdf 1 (data to be augmented)\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_1.shp\"))\n",
    "# Get df columns regarding raster class '190' (built-up) only\n",
    "df_col_list50 = list(df.columns[df.columns.str.endswith(\"_190\")])\n",
    "df_50 = df[df_col_list50]\n",
    "# join dataframes\n",
    "print(\"joining and saving temp gdf...\")\n",
    "gdf_final = pd.concat([shp_poly_gdf, df_50], axis=1)\n",
    "print(\"joined\")\n",
    "\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_2a.shp\"))\n",
    "print(\"temp gdf saved\")\n",
    "\n",
    "# remove temp .tif files:\n",
    "print(\"removing temp .tifs...\")\n",
    "for filepath in tqdm(temp_filepaths):\n",
    "    os.remove(filepath)\n",
    "print(\"temp .tifs removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes in raster: 19\n",
      "list of classes in raster [  0  10  11  20  30  40  50  60  62 100 110 120 122 130 160 170 180 190\n",
      " 210]\n",
      "number of columns in df: 54\n",
      "n° columns in df OK\n",
      "list of cols in df: ['prop_10', 'edge_10', 'frac_10', 'prop_30', 'edge_30', 'frac_30', 'prop_50', 'edge_50', 'frac_50', 'prop_190', 'edge_190', 'frac_190', 'edge_11', 'frac_11', 'prop_11', 'edge_40', 'frac_40', 'prop_40', 'edge_62', 'frac_62', 'prop_62', 'edge_100', 'frac_100', 'prop_100', 'edge_120', 'frac_120', 'prop_120', 'edge_122', 'frac_122', 'prop_122', 'edge_160', 'frac_160', 'prop_160', 'edge_210', 'frac_210', 'prop_210', 'edge_60', 'frac_60', 'prop_60', 'edge_170', 'frac_170', 'prop_170', 'edge_180', 'frac_180', 'prop_180', 'edge_20', 'frac_20', 'prop_20', 'edge_130', 'frac_130', 'prop_130', 'edge_110', 'frac_110', 'prop_110']\n",
      "extracted columns to join (class 190): ['prop_190', 'edge_190', 'frac_190']\n",
      "aggr_poly_gdf columns: 2\n",
      "df_50 columns (to join): 3\n",
      "shp_poly_gdf columns: 98\n",
      "gdf_final columns: 101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff',\n",
       " 'dtype': 'uint8',\n",
       " 'nodata': 0.0,\n",
       " 'width': 2198,\n",
       " 'height': 2295,\n",
       " 'count': 1,\n",
       " 'crs': CRS.from_epsg(4326),\n",
       " 'transform': Affine(0.0027777777777780025, 0.0, -8.599999999986286,\n",
       "        0.0, -0.002777777777778, 10.736111111104782)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "\n",
    "with rasterio.open(input_rasterpath) as src:\n",
    "    src_array = src.read(1)\n",
    "print(\"number of classes in raster:\", len(np.unique(src_array)))\n",
    "print(\"list of classes in raster\", np.unique(src_array))\n",
    "print(\"number of columns in df:\", len(df.columns.to_list()))\n",
    "if (len(df.columns.to_list())) != ((len(np.unique(src_array)) - 1) * 3):\n",
    "    print(\n",
    "        \"error: check n° columns in df, should be:\", (len(np.unique(src_array)) - 1) * 3\n",
    "    )\n",
    "else:\n",
    "    print(\"n° columns in df OK\")\n",
    "print(\"list of cols in df:\", df.columns.to_list())\n",
    "print(\"extracted columns to join (class 190):\", df_col_list50)\n",
    "print(\"aggr_poly_gdf columns:\", aggr_poly_gdf.shape[1])\n",
    "print(\"df_50 columns (to join):\", df_50.shape[1])\n",
    "print(\"shp_poly_gdf columns:\", shp_poly_gdf.shape[1])\n",
    "print(\"gdf_final columns:\", gdf_final.shape[1])\n",
    "src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragmenting raster...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230834fc190e4fb39ae587e26b986ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster fragmented\n",
      "calculating landscape metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dd2512d64542bfafe10052776df1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landscape metrics calculated\n",
      "joining and saving temp gdf...\n",
      "joined\n",
      "temp gdf saved\n",
      "removing temp .tifs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c339ad097c4d28be7d23f9478496dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp .tifs removed\n"
     ]
    }
   ],
   "source": [
    "# ANALYZE LAND COVER CLASSES WITH PYLANDSTATS\n",
    "\n",
    "# Input raster (with 2 built-up classes)\n",
    "\n",
    "input_rasterpath = path.join(\n",
    "    input_dir, \"ESACCI-LC-L4-LCCS-Map-300m-P1Y-2012-v2.0.7_rclassPrec.tif\"\n",
    ")\n",
    "\n",
    "# Fragment raster into pixel units (for faster calculus with pylandstats)\n",
    "\n",
    "print(\"fragmenting raster...\")\n",
    "temp_filepaths = []\n",
    "\n",
    "with rasterio.open(input_rasterpath) as src:\n",
    "    meta = src.meta.copy()\n",
    "    for un_identifier, geom in tqdm(\n",
    "        zip(aggr_poly_gdf[\"v001\"], aggr_poly_gdf[\"geometry\"]),\n",
    "        total=aggr_poly_gdf.shape[0],\n",
    "    ):\n",
    "        out_image, out_transform = mask.mask(\n",
    "            src, [geom], crop=True\n",
    "        )  # returns array with band values\n",
    "        meta.update(\n",
    "            {\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "            }\n",
    "        )\n",
    "        temp_filepath = path.join(dest_temp_dir, str(un_identifier) + \".tif\")\n",
    "        with rasterio.open(temp_filepath, \"w\", **meta) as dst:\n",
    "            dst.write(out_image[0], 1)\n",
    "        temp_filepaths.append(temp_filepath)\n",
    "\n",
    "print(\"raster fragmented\")\n",
    "\n",
    "# Calculate landscape metrics with pylandstats:\n",
    "\n",
    "# Create empty dataframe (columns = all raster classes)\n",
    "print(\"calculating landscape metrics...\")\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for filepath in tqdm(temp_filepaths):\n",
    "    ls = pls.Landscape(filepath)\n",
    "    class_metrics_df = ls.compute_class_metrics_df(\n",
    "        metrics=[\"proportion_of_landscape\", \"edge_density\", \"fractal_dimension_am\"]\n",
    "    )\n",
    "    df = df.append(class_metrics_df.stack(), ignore_index=True)\n",
    "df = df.fillna(0)\n",
    "df = df.rename(columns=lambda col: col[1][:4] + \"_\" + str(col[0]))\n",
    "print(\"landscape metrics calculated\")\n",
    "\n",
    "# Add attributes to geodataframe (join tables of attributes)\n",
    "\n",
    "# Get temp gdf 1 (data to be augmented)\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_2a.shp\"))\n",
    "# Get df columns regarding raster class '1' (precarious areas) only\n",
    "df_col_list50 = list(df.columns[df.columns.str.endswith(\"_1\")])\n",
    "df_50 = df[df_col_list50]\n",
    "# join dataframes\n",
    "print(\"joining and saving temp gdf...\")\n",
    "gdf_final = pd.concat([shp_poly_gdf, df_50], axis=1)\n",
    "print(\"joined\")\n",
    "\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_2b.shp\"))\n",
    "print(\"temp gdf saved\")\n",
    "\n",
    "\n",
    "# remove temp .tif files:\n",
    "print(\"removing temp .tifs...\")\n",
    "for filepath in tqdm(temp_filepaths):\n",
    "    os.remove(filepath)\n",
    "print(\"temp .tifs removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes in raster: 20\n",
      "list of classes in raster [  0   1  10  11  20  30  40  50  60  62 100 110 120 122 130 160 170 180\n",
      " 190 210]\n",
      "number of columns in df: 57\n",
      "n° columns in df OK\n",
      "list of cols in df: ['prop_1', 'edge_1', 'frac_1', 'prop_10', 'edge_10', 'frac_10', 'prop_30', 'edge_30', 'frac_30', 'prop_50', 'edge_50', 'frac_50', 'prop_190', 'edge_190', 'frac_190', 'edge_11', 'frac_11', 'prop_11', 'edge_40', 'frac_40', 'prop_40', 'edge_62', 'frac_62', 'prop_62', 'edge_100', 'frac_100', 'prop_100', 'edge_120', 'frac_120', 'prop_120', 'edge_122', 'frac_122', 'prop_122', 'edge_160', 'frac_160', 'prop_160', 'edge_210', 'frac_210', 'prop_210', 'edge_60', 'frac_60', 'prop_60', 'edge_170', 'frac_170', 'prop_170', 'edge_180', 'frac_180', 'prop_180', 'edge_20', 'frac_20', 'prop_20', 'edge_130', 'frac_130', 'prop_130', 'edge_110', 'frac_110', 'prop_110']\n",
      "extracted columns to join (class 1): ['prop_1', 'edge_1', 'frac_1']\n",
      "aggr_poly_gdf columns: 2\n",
      "df_50 columns (to join): 3\n",
      "shp_poly_gdf columns: 101\n",
      "gdf_final columns: 104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff',\n",
       " 'dtype': 'int32',\n",
       " 'nodata': 0.0,\n",
       " 'width': 2198,\n",
       " 'height': 2295,\n",
       " 'count': 1,\n",
       " 'crs': CRS.from_epsg(4326),\n",
       " 'transform': Affine(0.0027777777777780025, 0.0, -8.599999999986286,\n",
       "        0.0, -0.002777777777778, 10.736111111104782)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "\n",
    "with rasterio.open(input_rasterpath) as src:\n",
    "    src_array = src.read(1)\n",
    "print(\"number of classes in raster:\", len(np.unique(src_array)))\n",
    "print(\"list of classes in raster\", np.unique(src_array))\n",
    "print(\"number of columns in df:\", len(df.columns.to_list()))\n",
    "if (len(df.columns.to_list())) != ((len(np.unique(src_array)) - 1) * 3):\n",
    "    print(\n",
    "        \"error: check n° columns in df, should be:\", (len(np.unique(src_array)) - 1) * 3\n",
    "    )\n",
    "else:\n",
    "    print(\"n° columns in df OK\")\n",
    "print(\"list of cols in df:\", df.columns.to_list())\n",
    "print(\"extracted columns to join (class 1):\", df_col_list50)\n",
    "print(\"aggr_poly_gdf columns:\", aggr_poly_gdf.shape[1])\n",
    "print(\"df_50 columns (to join):\", df_50.shape[1])\n",
    "print(\"shp_poly_gdf columns:\", shp_poly_gdf.shape[1])\n",
    "print(\"gdf_final columns:\", gdf_final.shape[1])\n",
    "src.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density of built-up areas in buffer zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n",
      "<ipython-input-10-f11e5f61b0fa>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zs_df.den_med[zs_df.den_count==0] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "     den_count    den_med\n",
      "0          103   9.942583\n",
      "1            9   6.373635\n",
      "2            0        NaN\n",
      "3           18   6.076735\n",
      "4         1402  68.629402\n",
      "..         ...        ...\n",
      "336        157   9.725483\n",
      "337         79   9.650217\n",
      "338        699  15.908919\n",
      "339         81   8.112062\n",
      "340       1451  70.666916\n",
      "\n",
      "[341 rows x 2 columns]\n",
      "temp gdf saved\n"
     ]
    }
   ],
   "source": [
    "# Get input data\n",
    "\n",
    "shp_poly = path.join(input_dir, \"AGGR_DHS_buffer_temp_2b.shp\")\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_2b.shp\"))\n",
    "\n",
    "# Zonal stats\n",
    "\n",
    "with rasterio.open(path.join(input_dir, \"civ_ppp_2012_UNadj_masked.tif\")) as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = np.where(src.read(1) == src.meta[\"nodata\"], np.nan, src.read(1))\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=False, stats=\"count median\"\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(columns={\"count\": \"den_count\", \"median\": \"den_med\"})\n",
    "\n",
    "# replace 0s by NaN when there are no built-up pixels\n",
    "zs_df.den_med[zs_df.den_count == 0] = np.nan\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df)\n",
    "\n",
    "# JOIN TABLES (zonal raster stats to temp gdf)\n",
    "gdf_final = pd.concat([shp_poly_gdf, zs_df], axis=1)\n",
    "\n",
    "# Save temp file\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_3.shp\"))\n",
    "print(\"temp gdf saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of built areas by epoch of construction (GHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "     00_14_cnt  90_00_cnt  75_90_cnt  b75_cnt   pc_00_14   pc_90_00  \\\n",
      "0           18         15        211       38   6.382979   5.319149   \n",
      "1            1         10          7        8   3.846154  38.461538   \n",
      "2           24         42         34       55  15.483871  27.096774   \n",
      "3           33         17         77      163  11.379310   5.862069   \n",
      "4           40        510        960    10447   0.334532   4.265284   \n",
      "..         ...        ...        ...      ...        ...        ...   \n",
      "336        238        416          0      562  19.572368  34.210526   \n",
      "337         58        154         67      134  14.043584  37.288136   \n",
      "338        295        482       2123      904   7.754995  12.670873   \n",
      "339        146        160         46      306  22.188450  24.316109   \n",
      "340         13         66        346    11873   0.105708   0.536673   \n",
      "\n",
      "      pc_75_90     pc_b75  \n",
      "0    74.822695  13.475177  \n",
      "1    26.923077  30.769231  \n",
      "2    21.935484  35.483871  \n",
      "3    26.551724  56.206897  \n",
      "4     8.028770  87.371414  \n",
      "..         ...        ...  \n",
      "336   0.000000  46.217105  \n",
      "337  16.222760  32.445521  \n",
      "338  55.809674  23.764458  \n",
      "339   6.990881  46.504559  \n",
      "340   2.813466  96.544154  \n",
      "\n",
      "[341 rows x 8 columns]\n",
      "temp gdf saved\n"
     ]
    }
   ],
   "source": [
    "# Get input data\n",
    "\n",
    "shp_poly = path.join(input_dir, \"AGGR_DHS_buffer_temp_3.shp\")\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_3.shp\"))\n",
    "\n",
    "# Zonal stats\n",
    "\n",
    "with rasterio.open(\n",
    "    path.join(input_dir, \"GHS_merged_epsg4326_BuiltAllEpochs.tif\")\n",
    ") as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = src.read(1)\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=False, categorical=True\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(\n",
    "    columns={3.0: \"00_14_cnt\", 4.0: \"90_00_cnt\", 5.0: \"75_90_cnt\", 6.0: \"b75_cnt\"}\n",
    ")\n",
    "\n",
    "# replace NaN by 0s\n",
    "zs_df = zs_df.fillna(0)\n",
    "\n",
    "# from float to integer\n",
    "for v in zs_df.columns.to_list():\n",
    "    zs_df[v] = zs_df[v].astype(\"int32\")\n",
    "\n",
    "# calculate percentage of recently built areas\n",
    "zs_df[\"pc_00_14\"] = 100 * (\n",
    "    zs_df[\"00_14_cnt\"]\n",
    "    / (zs_df[\"90_00_cnt\"] + zs_df[\"75_90_cnt\"] + zs_df[\"00_14_cnt\"] + zs_df[\"b75_cnt\"])\n",
    ")\n",
    "\n",
    "# calculate percentage of fairly-recent built areas\n",
    "zs_df[\"pc_90_00\"] = 100 * (\n",
    "    zs_df[\"90_00_cnt\"]\n",
    "    / (zs_df[\"90_00_cnt\"] + zs_df[\"75_90_cnt\"] + zs_df[\"00_14_cnt\"] + zs_df[\"b75_cnt\"])\n",
    ")\n",
    "\n",
    "# calculate percentage of fairly-old built areas\n",
    "zs_df[\"pc_75_90\"] = 100 * (\n",
    "    zs_df[\"75_90_cnt\"]\n",
    "    / (zs_df[\"90_00_cnt\"] + zs_df[\"75_90_cnt\"] + zs_df[\"00_14_cnt\"] + zs_df[\"b75_cnt\"])\n",
    ")\n",
    "\n",
    "# calculate percentage of 'old' built areas\n",
    "zs_df[\"pc_b75\"] = 100 * (\n",
    "    zs_df[\"b75_cnt\"]\n",
    "    / (zs_df[\"90_00_cnt\"] + zs_df[\"75_90_cnt\"] + zs_df[\"00_14_cnt\"] + zs_df[\"b75_cnt\"])\n",
    ")\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df.iloc[:, 1:])  # drop column named 0.0 (problem with shp export)\n",
    "\n",
    "# JOIN TABLES (zonal raster stats to temp gdf)\n",
    "gdf_final = pd.concat([shp_poly_gdf, zs_df.iloc[:, 1:]], axis=1)\n",
    "\n",
    "# Save temp file\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_4.shp\"))\n",
    "print(\"temp gdf saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel count of built-up areas in buffer zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "      10.0   30.0  50.0  built_pix   11.0  40.0  62.0  100.0  120.0  122.0  \\\n",
      "0    789.0   11.0   2.0        9.0    0.0   0.0   0.0    0.0    0.0    0.0   \n",
      "1    110.0  649.0   4.0        1.0   40.0   8.0   0.0    0.0    0.0    0.0   \n",
      "2     99.0  546.0   0.0        0.0  101.0   7.0   0.0    0.0    0.0    0.0   \n",
      "3    707.0   17.0   9.0        2.0    0.0  71.0   2.0    1.0    4.0    0.0   \n",
      "4      0.0    0.0   0.0      126.0    0.0   0.0   0.0    0.0    4.0    0.0   \n",
      "..     ...    ...   ...        ...    ...   ...   ...    ...    ...    ...   \n",
      "336  801.0    0.0   0.0       14.0    0.0   0.0   0.0    0.0    0.0    0.0   \n",
      "337  699.0   80.0   0.0        7.0    0.0  27.0   3.0    0.0    0.0    0.0   \n",
      "338   58.0    3.0   0.0       63.0    2.0   0.0   0.0    0.0    2.0    0.0   \n",
      "339  801.0    8.0   0.0        8.0    0.0   0.0   0.0    0.0    0.0    0.0   \n",
      "340    0.0    0.0   0.0      131.0    0.0   0.0   0.0    0.0    0.0    0.0   \n",
      "\n",
      "     160.0  210.0  60.0  170.0  180.0  20.0  130.0  110.0  \n",
      "0      0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "1      0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "2      0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "3      0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "4      0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "..     ...    ...   ...    ...    ...   ...    ...    ...  \n",
      "336    0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "337    0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "338    0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "339    0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "340    0.0    0.0   0.0    0.0    0.0   0.0    0.0    0.0  \n",
      "\n",
      "[341 rows x 18 columns]\n",
      "temp gdf saved\n"
     ]
    }
   ],
   "source": [
    "# Get input data\n",
    "\n",
    "shp_poly = path.join(input_dir, \"AGGR_DHS_buffer_temp_4.shp\")\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_4.shp\"))\n",
    "\n",
    "# Zonal stats\n",
    "\n",
    "with rasterio.open(\n",
    "    path.join(input_dir, \"ESACCI-LC-L4-LCCS-Map-300m-P1Y-2012-v2.0.7.tif\")\n",
    ") as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = np.where(src.read(1) == src.meta[\"nodata\"], np.nan, src.read(1))\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=False, categorical=True\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(columns={190: \"built_pix\"})  # count of built up pixels\n",
    "\n",
    "# replace NaN by 0s\n",
    "zs_df = zs_df.fillna(0)\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df)\n",
    "\n",
    "# JOIN TABLES (zonal raster stats to temp gdf)\n",
    "gdf_final = pd.concat([shp_poly_gdf, zs_df[\"built_pix\"]], axis=1)\n",
    "\n",
    "# Save temp file\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_5.shp\"))\n",
    "print(\"temp gdf saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road infrastructures : availability (length) and morphology\n",
    "\n",
    "NOTE 1: OSM data was 'cleaned' following the protocol by Karduni et al. (2016), DOI: 10.1038/sdata.2016.46 --> output is the shapefile named \"Edges_gis_osm_roads_free_1_4326\"  \n",
    "NOTE 2: Only roads accessible by motorised vehicles were considered (fclass removed: 'cycleway',  'footway',  'pedestrian',  'track' and  'track_grade1' to  'track_grade5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get source file\n",
    "roads = gpd.read_file(\"data/raw/osm/output/Edges_gis_osm_roads_free_1_filtered.shp\")\n",
    "# Change CRS\n",
    "roads = roads.to_crs(\"EPSG:3857\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road morphology\n",
    "#### Linearity of each segment\n",
    "Calculates linearity of each LineString object in given GeoDataFrame  \n",
    "Formula: len. euclidean / len. segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate linearity index\n",
    "edg_lin = momepy.Linearity(roads)\n",
    "\n",
    "# Add column to edges GDF with linearity index\n",
    "roads[\"linearity\"] = edg_lin.series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification of road linearity\n",
    "aiming close-to-normal distribution among classes (classification calibrated by quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-bb057ee71217>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  roads.lin_class[roads.linearity>=\n",
      "<ipython-input-15-bb057ee71217>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  roads.lin_class[roads.linearity>=\n",
      "<ipython-input-15-bb057ee71217>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  roads.lin_class[roads.linearity>=\n",
      "<ipython-input-15-bb057ee71217>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  roads.lin_class[roads.linearity>=\n",
      "<ipython-input-15-bb057ee71217>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  roads.lin_class[roads.linearity>=\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set \"lin_class\" attributes\n",
    "roads[\"lin_class\"] = \"\"\n",
    "\n",
    "roads.lin_class[roads.linearity >= 0] = \"1\"  # lowest linearity\n",
    "roads.lin_class[\n",
    "    roads.linearity >= np.nanquantile(roads.linearity, 0.20)\n",
    "] = \"2\"  # Low-linearity threshold\n",
    "roads.lin_class[\n",
    "    roads.linearity >= np.nanquantile(roads.linearity, 0.40)\n",
    "] = \"3\"  # Mid-linearity threshold\n",
    "roads.lin_class[\n",
    "    roads.linearity >= np.nanquantile(roads.linearity, 0.80)\n",
    "] = \"4\"  # High-linearity threshold\n",
    "roads.lin_class[\n",
    "    roads.linearity >= np.nanquantile(roads.linearity, 0.95)\n",
    "] = \"5\"  # High-linearity threshold\n",
    "\n",
    "plt.hist(roads[\"lin_class\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clip elements (buffer zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clipping geometries...\n"
     ]
    }
   ],
   "source": [
    "# Get clipping extent\n",
    "crop_ext = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer.shp\"))\n",
    "\n",
    "# Set CRS\n",
    "roads = roads.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Clip geometries\n",
    "print(\"clipping geometries...\")\n",
    "roads_CIV_2 = gpd.overlay(roads, crop_ext, how=\"intersection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate road data and save temp shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v001</th>\n",
       "      <th>prop_10</th>\n",
       "      <th>edge_10</th>\n",
       "      <th>frac_10</th>\n",
       "      <th>prop_30</th>\n",
       "      <th>edge_30</th>\n",
       "      <th>frac_30</th>\n",
       "      <th>prop_50</th>\n",
       "      <th>edge_50</th>\n",
       "      <th>frac_50</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_75_90</th>\n",
       "      <th>pc_b75</th>\n",
       "      <th>built_pix</th>\n",
       "      <th>geometry</th>\n",
       "      <th>RdLenTot</th>\n",
       "      <th>RdLen_LI1</th>\n",
       "      <th>RdLen_LI2</th>\n",
       "      <th>RdLen_LI3</th>\n",
       "      <th>RdLen_LI4</th>\n",
       "      <th>RdLen_LI5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>97.287300</td>\n",
       "      <td>1.642417e+05</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>1.356350</td>\n",
       "      <td>9.321825e+04</td>\n",
       "      <td>0.964427</td>\n",
       "      <td>0.246609</td>\n",
       "      <td>22194.821208</td>\n",
       "      <td>0.989369</td>\n",
       "      <td>...</td>\n",
       "      <td>74.822695</td>\n",
       "      <td>13.475177</td>\n",
       "      <td>9.0</td>\n",
       "      <td>POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...</td>\n",
       "      <td>80.931200</td>\n",
       "      <td>65.915491</td>\n",
       "      <td>11.664737</td>\n",
       "      <td>2.415456</td>\n",
       "      <td>0.835918</td>\n",
       "      <td>0.099597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.546798</td>\n",
       "      <td>8.911330e+05</td>\n",
       "      <td>0.790827</td>\n",
       "      <td>79.926108</td>\n",
       "      <td>1.325616e+06</td>\n",
       "      <td>0.484783</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>44334.975369</td>\n",
       "      <td>0.979785</td>\n",
       "      <td>...</td>\n",
       "      <td>26.923077</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...</td>\n",
       "      <td>12.063733</td>\n",
       "      <td>12.063733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.147410</td>\n",
       "      <td>9.274900e+05</td>\n",
       "      <td>0.852884</td>\n",
       "      <td>72.509960</td>\n",
       "      <td>1.950598e+06</td>\n",
       "      <td>0.383876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.935484</td>\n",
       "      <td>35.483871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...</td>\n",
       "      <td>45.594455</td>\n",
       "      <td>36.652531</td>\n",
       "      <td>7.962702</td>\n",
       "      <td>0.564346</td>\n",
       "      <td>0.364398</td>\n",
       "      <td>0.050478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>86.961870</td>\n",
       "      <td>1.009594e+06</td>\n",
       "      <td>0.549495</td>\n",
       "      <td>2.091021</td>\n",
       "      <td>1.815498e+05</td>\n",
       "      <td>0.937940</td>\n",
       "      <td>1.107011</td>\n",
       "      <td>115129.151292</td>\n",
       "      <td>0.983928</td>\n",
       "      <td>...</td>\n",
       "      <td>26.551724</td>\n",
       "      <td>56.206897</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...</td>\n",
       "      <td>22.498118</td>\n",
       "      <td>17.402302</td>\n",
       "      <td>5.095816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.028770</td>\n",
       "      <td>87.371414</td>\n",
       "      <td>126.0</td>\n",
       "      <td>POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...</td>\n",
       "      <td>189.070631</td>\n",
       "      <td>19.331187</td>\n",
       "      <td>20.917809</td>\n",
       "      <td>37.372213</td>\n",
       "      <td>87.021730</td>\n",
       "      <td>24.427693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>348.0</td>\n",
       "      <td>98.282209</td>\n",
       "      <td>1.501840e+05</td>\n",
       "      <td>0.863970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.217105</td>\n",
       "      <td>14.0</td>\n",
       "      <td>POLYGON ((-5.67087 6.36162, -5.67109 6.35724, ...</td>\n",
       "      <td>36.780442</td>\n",
       "      <td>31.085973</td>\n",
       "      <td>4.865576</td>\n",
       "      <td>0.678314</td>\n",
       "      <td>0.145157</td>\n",
       "      <td>0.005420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>349.0</td>\n",
       "      <td>85.661765</td>\n",
       "      <td>1.244118e+06</td>\n",
       "      <td>0.500234</td>\n",
       "      <td>9.803922</td>\n",
       "      <td>9.088235e+05</td>\n",
       "      <td>0.879682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.222760</td>\n",
       "      <td>32.445521</td>\n",
       "      <td>7.0</td>\n",
       "      <td>POLYGON ((-5.23281 6.98753, -5.23303 6.98316, ...</td>\n",
       "      <td>50.610026</td>\n",
       "      <td>13.758455</td>\n",
       "      <td>16.878024</td>\n",
       "      <td>17.008553</td>\n",
       "      <td>2.026587</td>\n",
       "      <td>0.938407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>350.0</td>\n",
       "      <td>45.312500</td>\n",
       "      <td>1.068750e+06</td>\n",
       "      <td>0.811826</td>\n",
       "      <td>2.343750</td>\n",
       "      <td>1.406250e+05</td>\n",
       "      <td>0.992913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.809674</td>\n",
       "      <td>23.764458</td>\n",
       "      <td>63.0</td>\n",
       "      <td>POLYGON ((-3.18245 7.13638, -3.18254 7.13464, ...</td>\n",
       "      <td>104.856188</td>\n",
       "      <td>18.352986</td>\n",
       "      <td>18.921388</td>\n",
       "      <td>24.240169</td>\n",
       "      <td>33.543664</td>\n",
       "      <td>9.797981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>351.0</td>\n",
       "      <td>98.041616</td>\n",
       "      <td>1.938800e+05</td>\n",
       "      <td>0.830987</td>\n",
       "      <td>0.979192</td>\n",
       "      <td>1.057528e+05</td>\n",
       "      <td>0.961448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.990881</td>\n",
       "      <td>46.504559</td>\n",
       "      <td>8.0</td>\n",
       "      <td>POLYGON ((-6.46786 6.65822, -6.46807 6.65385, ...</td>\n",
       "      <td>59.005977</td>\n",
       "      <td>27.400119</td>\n",
       "      <td>12.945295</td>\n",
       "      <td>12.490090</td>\n",
       "      <td>4.307423</td>\n",
       "      <td>1.863051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>352.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.813466</td>\n",
       "      <td>96.544154</td>\n",
       "      <td>131.0</td>\n",
       "      <td>POLYGON ((-5.01604 7.69501, -5.01612 7.69326, ...</td>\n",
       "      <td>197.338341</td>\n",
       "      <td>27.265578</td>\n",
       "      <td>23.611720</td>\n",
       "      <td>50.086847</td>\n",
       "      <td>75.488682</td>\n",
       "      <td>20.885515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      v001    prop_10       edge_10   frac_10    prop_30       edge_30  \\\n",
       "0      1.0  97.287300  1.642417e+05  0.866345   1.356350  9.321825e+04   \n",
       "1      2.0  13.546798  8.911330e+05  0.790827  79.926108  1.325616e+06   \n",
       "2      3.0  13.147410  9.274900e+05  0.852884  72.509960  1.950598e+06   \n",
       "3      4.0  86.961870  1.009594e+06  0.549495   2.091021  1.815498e+05   \n",
       "4      5.0   0.000000  0.000000e+00  0.000000   0.000000  0.000000e+00   \n",
       "..     ...        ...           ...       ...        ...           ...   \n",
       "336  348.0  98.282209  1.501840e+05  0.863970   0.000000  0.000000e+00   \n",
       "337  349.0  85.661765  1.244118e+06  0.500234   9.803922  9.088235e+05   \n",
       "338  350.0  45.312500  1.068750e+06  0.811826   2.343750  1.406250e+05   \n",
       "339  351.0  98.041616  1.938800e+05  0.830987   0.979192  1.057528e+05   \n",
       "340  352.0   0.000000  0.000000e+00  0.000000   0.000000  0.000000e+00   \n",
       "\n",
       "      frac_30   prop_50        edge_50   frac_50  ...   pc_75_90     pc_b75  \\\n",
       "0    0.964427  0.246609   22194.821208  0.989369  ...  74.822695  13.475177   \n",
       "1    0.484783  0.492611   44334.975369  0.979785  ...  26.923077  30.769231   \n",
       "2    0.383876  0.000000       0.000000  0.000000  ...  21.935484  35.483871   \n",
       "3    0.937940  1.107011  115129.151292  0.983928  ...  26.551724  56.206897   \n",
       "4    0.000000  0.000000       0.000000  0.000000  ...   8.028770  87.371414   \n",
       "..        ...       ...            ...       ...  ...        ...        ...   \n",
       "336  0.000000  0.000000       0.000000  0.000000  ...   0.000000  46.217105   \n",
       "337  0.879682  0.000000       0.000000  0.000000  ...  16.222760  32.445521   \n",
       "338  0.992913  0.000000       0.000000  0.000000  ...  55.809674  23.764458   \n",
       "339  0.961448  0.000000       0.000000  0.000000  ...   6.990881  46.504559   \n",
       "340  0.000000  0.000000       0.000000  0.000000  ...   2.813466  96.544154   \n",
       "\n",
       "     built_pix                                           geometry    RdLenTot  \\\n",
       "0          9.0  POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...   80.931200   \n",
       "1          1.0  POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...   12.063733   \n",
       "2          0.0  POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...   45.594455   \n",
       "3          2.0  POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...   22.498118   \n",
       "4        126.0  POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...  189.070631   \n",
       "..         ...                                                ...         ...   \n",
       "336       14.0  POLYGON ((-5.67087 6.36162, -5.67109 6.35724, ...   36.780442   \n",
       "337        7.0  POLYGON ((-5.23281 6.98753, -5.23303 6.98316, ...   50.610026   \n",
       "338       63.0  POLYGON ((-3.18245 7.13638, -3.18254 7.13464, ...  104.856188   \n",
       "339        8.0  POLYGON ((-6.46786 6.65822, -6.46807 6.65385, ...   59.005977   \n",
       "340      131.0  POLYGON ((-5.01604 7.69501, -5.01612 7.69326, ...  197.338341   \n",
       "\n",
       "     RdLen_LI1  RdLen_LI2  RdLen_LI3  RdLen_LI4  RdLen_LI5  \n",
       "0    65.915491  11.664737   2.415456   0.835918   0.099597  \n",
       "1    12.063733   0.000000   0.000000   0.000000   0.000000  \n",
       "2    36.652531   7.962702   0.564346   0.364398   0.050478  \n",
       "3    17.402302   5.095816   0.000000   0.000000   0.000000  \n",
       "4    19.331187  20.917809  37.372213  87.021730  24.427693  \n",
       "..         ...        ...        ...        ...        ...  \n",
       "336  31.085973   4.865576   0.678314   0.145157   0.005420  \n",
       "337  13.758455  16.878024  17.008553   2.026587   0.938407  \n",
       "338  18.352986  18.921388  24.240169  33.543664   9.797981  \n",
       "339  27.400119  12.945295  12.490090   4.307423   1.863051  \n",
       "340  27.265578  23.611720  50.086847  75.488682  20.885515  \n",
       "\n",
       "[341 rows x 121 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input data\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_5.shp\"))\n",
    "\n",
    "# Calculate length (m) of edges\n",
    "roads_CIV_2 = roads_CIV_2.to_crs(\"EPSG:3857\")  # to metric system\n",
    "roads_CIV_2[\"Rd_Len\"] = roads_CIV_2[\"geometry\"].length  # add col with length\n",
    "\n",
    "# Aggregate: length (km) of edges, for each buffer zone :\n",
    "rd_len_data = (roads_CIV_2.groupby(\"v001\").agg(\"sum\")[\"Rd_Len\"]) / 1000\n",
    "\n",
    "gdf_final_t1 = shp_poly_gdf.merge(rd_len_data, on=\"v001\", how=\"left\")\n",
    "gdf_final_t1 = gdf_final_t1.rename(columns={\"Rd_Len\": \"RdLenTot\"})\n",
    "\n",
    "# Aggregate: length (km) of edges, by LINEARITY class, for each 5x5km pixel :\n",
    "rd_len_LI_data = (\n",
    "    roads_CIV_2.groupby([\"v001\", \"lin_class\"]).agg(\"sum\")[\"Rd_Len\"]\n",
    ") / 1000\n",
    "\n",
    "rd_len_LI_data_1 = rd_len_LI_data.iloc[\n",
    "    rd_len_LI_data.index.get_level_values(\"lin_class\") == \"1\"\n",
    "]\n",
    "rd_len_LI_data_2 = rd_len_LI_data.iloc[\n",
    "    rd_len_LI_data.index.get_level_values(\"lin_class\") == \"2\"\n",
    "]\n",
    "rd_len_LI_data_3 = rd_len_LI_data.iloc[\n",
    "    rd_len_LI_data.index.get_level_values(\"lin_class\") == \"3\"\n",
    "]\n",
    "rd_len_LI_data_4 = rd_len_LI_data.iloc[\n",
    "    rd_len_LI_data.index.get_level_values(\"lin_class\") == \"4\"\n",
    "]\n",
    "rd_len_LI_data_5 = rd_len_LI_data.iloc[\n",
    "    rd_len_LI_data.index.get_level_values(\"lin_class\") == \"5\"\n",
    "]\n",
    "\n",
    "gdf_final_t2 = gdf_final_t1.merge(rd_len_LI_data_1, on=\"v001\", how=\"left\")\n",
    "gdf_final_t2 = gdf_final_t2.rename(columns={\"Rd_Len\": \"RdLen_LI1\"})\n",
    "gdf_final_t3 = gdf_final_t2.merge(rd_len_LI_data_2, on=\"v001\", how=\"left\")\n",
    "gdf_final_t3 = gdf_final_t3.rename(columns={\"Rd_Len\": \"RdLen_LI2\"})\n",
    "gdf_final_t4 = gdf_final_t3.merge(rd_len_LI_data_3, on=\"v001\", how=\"left\")\n",
    "gdf_final_t4 = gdf_final_t4.rename(columns={\"Rd_Len\": \"RdLen_LI3\"})\n",
    "gdf_final_t5 = gdf_final_t4.merge(rd_len_LI_data_4, on=\"v001\", how=\"left\")\n",
    "gdf_final_t5 = gdf_final_t5.rename(columns={\"Rd_Len\": \"RdLen_LI4\"})\n",
    "gdf_final_t6 = gdf_final_t5.merge(rd_len_LI_data_5, on=\"v001\", how=\"left\")\n",
    "gdf_final_t6 = gdf_final_t6.rename(columns={\"Rd_Len\": \"RdLen_LI5\"})\n",
    "\n",
    "# Replace NaNs by 0\n",
    "list_col_names = []\n",
    "for v in list(gdf_final_t6.columns.to_list()):\n",
    "    if str(v).startswith(\"RdLen\"):\n",
    "        list_col_names = list_col_names + [v]\n",
    "\n",
    "gdf_final = gdf_final_t6.copy()\n",
    "\n",
    "for v in list_col_names:\n",
    "    if gdf_final[v].isna().any():\n",
    "        gdf_final[v] = gdf_final[v].fillna(0)\n",
    "\n",
    "gdf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp gdf saved\n"
     ]
    }
   ],
   "source": [
    "# Save temp file\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_6.shp\"))\n",
    "print(\"temp gdf saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "        ac_ppt16\n",
      "0    1617.433322\n",
      "1    1160.712479\n",
      "2    1277.799995\n",
      "3    1200.377780\n",
      "4    1072.674988\n",
      "..           ...\n",
      "336  1032.511122\n",
      "337  1129.133341\n",
      "338  1226.424957\n",
      "339   916.766669\n",
      "340  1072.674988\n",
      "\n",
      "[341 rows x 1 columns]\n",
      "Look for NaNs:\n",
      "False    341\n",
      "Name: ac_ppt16, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get input data\n",
    "\n",
    "shp_poly = path.join(input_dir, \"AGGR_DHS_buffer_temp_6.shp\")\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_6.shp\"))\n",
    "\n",
    "# Zonal stats : accumulated precipitation (mm)\n",
    "\n",
    "with rasterio.open(\n",
    "    path.join(input_dir, \"TerraClimate_ppt_2012_bboxciv_acPPT.tif\")\n",
    ") as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = np.where(src.read(1) == src.meta[\"nodata\"], np.nan, src.read(1))\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=True, stats=\"mean\"\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(columns={\"mean\": \"ac_ppt16\"})\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df)\n",
    "\n",
    "print(\"Look for NaNs:\")\n",
    "print(zs_df.ac_ppt16.isna().value_counts())\n",
    "\n",
    "if zs_df.ac_ppt16.isna().any() is False:\n",
    "    gdf_final = pd.concat([gdf_final, zs_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "       mn_ppt16\n",
      "0    134.786111\n",
      "1     96.726042\n",
      "2    106.483334\n",
      "3    100.031481\n",
      "4     89.389585\n",
      "..          ...\n",
      "336   86.042593\n",
      "337   94.094444\n",
      "338  102.202084\n",
      "339   76.397221\n",
      "340   89.389585\n",
      "\n",
      "[341 rows x 1 columns]\n",
      "Look for NaNs:\n",
      "False    341\n",
      "Name: mn_ppt16, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Zonal stats : mean precipitation (mm)\n",
    "\n",
    "with rasterio.open(\n",
    "    path.join(input_dir, \"TerraClimate_ppt_2012_bboxciv_MEAN.tif\")\n",
    ") as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = np.where(src.read(1) == src.meta[\"nodata\"], np.nan, src.read(1))\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=True, stats=\"mean\"\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(columns={\"mean\": \"mn_ppt16\"})\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df)\n",
    "\n",
    "print(\"Look for NaNs:\")\n",
    "print(zs_df.mn_ppt16.isna().value_counts())\n",
    "\n",
    "if zs_df.mn_ppt16.isna().any() is False:\n",
    "    gdf_final = pd.concat([gdf_final, zs_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "     std_ppt16\n",
      "0    65.901251\n",
      "1    61.874496\n",
      "2    69.286409\n",
      "3    57.573416\n",
      "4    52.837522\n",
      "..         ...\n",
      "336  51.057771\n",
      "337  50.277286\n",
      "338  53.734177\n",
      "339  44.636770\n",
      "340  52.837522\n",
      "\n",
      "[341 rows x 1 columns]\n",
      "Look for NaNs:\n",
      "False    341\n",
      "Name: std_ppt16, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Zonal stats : standard deviation of precipitation (mm)\n",
    "\n",
    "with rasterio.open(\n",
    "    path.join(input_dir, \"TerraClimate_ppt_2012_bboxciv_STD.tif\")\n",
    ") as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = np.where(src.read(1) == src.meta[\"nodata\"], np.nan, src.read(1))\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=True, stats=\"mean\"\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(columns={\"mean\": \"std_ppt16\"})\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df)\n",
    "\n",
    "print(\"Look for NaNs:\")\n",
    "print(zs_df.std_ppt16.isna().value_counts())\n",
    "\n",
    "if zs_df.std_ppt16.isna().any() is False:\n",
    "    gdf_final = pd.concat([gdf_final, zs_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "     mn_tmax16\n",
      "0    30.992685\n",
      "1    31.332812\n",
      "2    31.682962\n",
      "3    31.360556\n",
      "4    31.968540\n",
      "..         ...\n",
      "336  30.270647\n",
      "337  31.591019\n",
      "338  31.236666\n",
      "339  30.875462\n",
      "340  31.968540\n",
      "\n",
      "[341 rows x 1 columns]\n",
      "Look for NaNs:\n",
      "False    341\n",
      "Name: mn_tmax16, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Zonal stats : mean of maximum temperatures ('tmax')\n",
    "\n",
    "with rasterio.open(\n",
    "    path.join(input_dir, \"TerraClimate_tmax_2012_bboxciv_MEAN.tif\")\n",
    ") as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = np.where(src.read(1) == src.meta[\"nodata\"], np.nan, src.read(1))\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=True, stats=\"mean\"\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(columns={\"mean\": \"mn_tmax16\"})\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df)\n",
    "\n",
    "print(\"Look for NaNs:\")\n",
    "print(zs_df.mn_tmax16.isna().value_counts())\n",
    "\n",
    "if zs_df.mn_tmax16.isna().any() is False:\n",
    "    gdf_final = pd.concat([gdf_final, zs_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/miniconda3/envs/LS_Metrics/lib/python3.8/site-packages/rasterstats/io.py:302: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs_df :\n",
      "     std_tmx16\n",
      "0     1.791916\n",
      "1     1.739660\n",
      "2     1.886310\n",
      "3     2.301283\n",
      "4     2.091782\n",
      "..         ...\n",
      "336   1.643358\n",
      "337   1.799232\n",
      "338   2.065269\n",
      "339   1.749894\n",
      "340   2.091782\n",
      "\n",
      "[341 rows x 1 columns]\n",
      "Look for NaNs:\n",
      "False    341\n",
      "Name: std_tmx16, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Zonal stats : STD of maximum temperatures ('tmax')\n",
    "\n",
    "with rasterio.open(\n",
    "    path.join(input_dir, \"TerraClimate_tmax_2012_bboxciv_STD.tif\")\n",
    ") as src:\n",
    "    affine = src.meta[\"transform\"]\n",
    "    array = np.where(src.read(1) == src.meta[\"nodata\"], np.nan, src.read(1))\n",
    "\n",
    "zs = zonal_stats(\n",
    "    shp_poly, array, affine=affine, all_touched=True, stats=\"mean\"\n",
    ")  # result will be in 'dictionary' format\n",
    "\n",
    "# SET RASTER STATS: from DICTIONARY to DATAFRAME (w/ pandas)\n",
    "\n",
    "zs_df = pd.DataFrame(zs)\n",
    "\n",
    "# rename columns\n",
    "zs_df = zs_df.rename(columns={\"mean\": \"std_tmx16\"})\n",
    "\n",
    "print(\"zs_df :\")\n",
    "print(zs_df)\n",
    "\n",
    "print(\"Look for NaNs:\")\n",
    "print(zs_df.std_tmx16.isna().value_counts())\n",
    "\n",
    "if zs_df.std_tmx16.isna().any() is False:\n",
    "    gdf_final = pd.concat([gdf_final, zs_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp gdf saved\n"
     ]
    }
   ],
   "source": [
    "# Save temp file\n",
    "gdf_final.to_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_7.shp\"))\n",
    "print(\"temp gdf saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Calculate new fields:\n",
    "### Independent variables derived from land cover classes, road classes and zonal stats in buffer zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v001</th>\n",
       "      <th>prop_10</th>\n",
       "      <th>edge_10</th>\n",
       "      <th>frac_10</th>\n",
       "      <th>prop_30</th>\n",
       "      <th>edge_30</th>\n",
       "      <th>frac_30</th>\n",
       "      <th>prop_50</th>\n",
       "      <th>edge_50</th>\n",
       "      <th>frac_50</th>\n",
       "      <th>...</th>\n",
       "      <th>RdLen_LI2</th>\n",
       "      <th>RdLen_LI3</th>\n",
       "      <th>RdLen_LI4</th>\n",
       "      <th>RdLen_LI5</th>\n",
       "      <th>ac_ppt16</th>\n",
       "      <th>mn_ppt16</th>\n",
       "      <th>std_ppt16</th>\n",
       "      <th>mn_tmax16</th>\n",
       "      <th>std_tmx16</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>97.287300</td>\n",
       "      <td>1.642417e+05</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>1.356350</td>\n",
       "      <td>9.321825e+04</td>\n",
       "      <td>0.964427</td>\n",
       "      <td>0.246609</td>\n",
       "      <td>22194.821208</td>\n",
       "      <td>0.989369</td>\n",
       "      <td>...</td>\n",
       "      <td>11.664737</td>\n",
       "      <td>2.415456</td>\n",
       "      <td>0.835918</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>1617.433322</td>\n",
       "      <td>134.786111</td>\n",
       "      <td>65.901251</td>\n",
       "      <td>30.992685</td>\n",
       "      <td>1.791916</td>\n",
       "      <td>POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.546798</td>\n",
       "      <td>8.911330e+05</td>\n",
       "      <td>0.790827</td>\n",
       "      <td>79.926108</td>\n",
       "      <td>1.325616e+06</td>\n",
       "      <td>0.484783</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>44334.975369</td>\n",
       "      <td>0.979785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1160.712479</td>\n",
       "      <td>96.726042</td>\n",
       "      <td>61.874496</td>\n",
       "      <td>31.332812</td>\n",
       "      <td>1.739660</td>\n",
       "      <td>POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.147410</td>\n",
       "      <td>9.274900e+05</td>\n",
       "      <td>0.852884</td>\n",
       "      <td>72.509960</td>\n",
       "      <td>1.950598e+06</td>\n",
       "      <td>0.383876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.962702</td>\n",
       "      <td>0.564346</td>\n",
       "      <td>0.364398</td>\n",
       "      <td>0.050478</td>\n",
       "      <td>1277.799995</td>\n",
       "      <td>106.483334</td>\n",
       "      <td>69.286409</td>\n",
       "      <td>31.682962</td>\n",
       "      <td>1.886310</td>\n",
       "      <td>POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>86.961870</td>\n",
       "      <td>1.009594e+06</td>\n",
       "      <td>0.549495</td>\n",
       "      <td>2.091021</td>\n",
       "      <td>1.815498e+05</td>\n",
       "      <td>0.937940</td>\n",
       "      <td>1.107011</td>\n",
       "      <td>115129.151292</td>\n",
       "      <td>0.983928</td>\n",
       "      <td>...</td>\n",
       "      <td>5.095816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.377780</td>\n",
       "      <td>100.031481</td>\n",
       "      <td>57.573416</td>\n",
       "      <td>31.360556</td>\n",
       "      <td>2.301283</td>\n",
       "      <td>POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.917809</td>\n",
       "      <td>37.372213</td>\n",
       "      <td>87.021730</td>\n",
       "      <td>24.427693</td>\n",
       "      <td>1072.674988</td>\n",
       "      <td>89.389585</td>\n",
       "      <td>52.837522</td>\n",
       "      <td>31.968540</td>\n",
       "      <td>2.091782</td>\n",
       "      <td>POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v001    prop_10       edge_10   frac_10    prop_30       edge_30   frac_30  \\\n",
       "0   1.0  97.287300  1.642417e+05  0.866345   1.356350  9.321825e+04  0.964427   \n",
       "1   2.0  13.546798  8.911330e+05  0.790827  79.926108  1.325616e+06  0.484783   \n",
       "2   3.0  13.147410  9.274900e+05  0.852884  72.509960  1.950598e+06  0.383876   \n",
       "3   4.0  86.961870  1.009594e+06  0.549495   2.091021  1.815498e+05  0.937940   \n",
       "4   5.0   0.000000  0.000000e+00  0.000000   0.000000  0.000000e+00  0.000000   \n",
       "\n",
       "    prop_50        edge_50   frac_50  ...  RdLen_LI2  RdLen_LI3  RdLen_LI4  \\\n",
       "0  0.246609   22194.821208  0.989369  ...  11.664737   2.415456   0.835918   \n",
       "1  0.492611   44334.975369  0.979785  ...   0.000000   0.000000   0.000000   \n",
       "2  0.000000       0.000000  0.000000  ...   7.962702   0.564346   0.364398   \n",
       "3  1.107011  115129.151292  0.983928  ...   5.095816   0.000000   0.000000   \n",
       "4  0.000000       0.000000  0.000000  ...  20.917809  37.372213  87.021730   \n",
       "\n",
       "   RdLen_LI5     ac_ppt16    mn_ppt16  std_ppt16  mn_tmax16  std_tmx16  \\\n",
       "0   0.099597  1617.433322  134.786111  65.901251  30.992685   1.791916   \n",
       "1   0.000000  1160.712479   96.726042  61.874496  31.332812   1.739660   \n",
       "2   0.050478  1277.799995  106.483334  69.286409  31.682962   1.886310   \n",
       "3   0.000000  1200.377780  100.031481  57.573416  31.360556   2.301283   \n",
       "4  24.427693  1072.674988   89.389585  52.837522  31.968540   2.091782   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...  \n",
       "1  POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...  \n",
       "2  POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...  \n",
       "3  POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...  \n",
       "4  POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "shp_poly_gdf = gpd.read_file(path.join(input_dir, \"AGGR_DHS_buffer_temp_7.shp\"))\n",
    "shp_poly_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-61b5fb6fe726>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"rdTt_BtHa\"][shp_poly_gdf['built_pix']>0] = (shp_poly_gdf['RdLenTot']/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v001</th>\n",
       "      <th>prop_10</th>\n",
       "      <th>edge_10</th>\n",
       "      <th>frac_10</th>\n",
       "      <th>prop_30</th>\n",
       "      <th>edge_30</th>\n",
       "      <th>frac_30</th>\n",
       "      <th>prop_50</th>\n",
       "      <th>edge_50</th>\n",
       "      <th>frac_50</th>\n",
       "      <th>...</th>\n",
       "      <th>RdLen_LI3</th>\n",
       "      <th>RdLen_LI4</th>\n",
       "      <th>RdLen_LI5</th>\n",
       "      <th>ac_ppt16</th>\n",
       "      <th>mn_ppt16</th>\n",
       "      <th>std_ppt16</th>\n",
       "      <th>mn_tmax16</th>\n",
       "      <th>std_tmx16</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rdTt_BtHa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>97.287300</td>\n",
       "      <td>1.642417e+05</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>1.356350</td>\n",
       "      <td>9.321825e+04</td>\n",
       "      <td>0.964427</td>\n",
       "      <td>0.246609</td>\n",
       "      <td>22194.821208</td>\n",
       "      <td>0.989369</td>\n",
       "      <td>...</td>\n",
       "      <td>2.415456</td>\n",
       "      <td>0.835918</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>1617.433322</td>\n",
       "      <td>134.786111</td>\n",
       "      <td>65.901251</td>\n",
       "      <td>30.992685</td>\n",
       "      <td>1.791916</td>\n",
       "      <td>POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...</td>\n",
       "      <td>8.992356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.546798</td>\n",
       "      <td>8.911330e+05</td>\n",
       "      <td>0.790827</td>\n",
       "      <td>79.926108</td>\n",
       "      <td>1.325616e+06</td>\n",
       "      <td>0.484783</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>44334.975369</td>\n",
       "      <td>0.979785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1160.712479</td>\n",
       "      <td>96.726042</td>\n",
       "      <td>61.874496</td>\n",
       "      <td>31.332812</td>\n",
       "      <td>1.739660</td>\n",
       "      <td>POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...</td>\n",
       "      <td>12.063733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.147410</td>\n",
       "      <td>9.274900e+05</td>\n",
       "      <td>0.852884</td>\n",
       "      <td>72.509960</td>\n",
       "      <td>1.950598e+06</td>\n",
       "      <td>0.383876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564346</td>\n",
       "      <td>0.364398</td>\n",
       "      <td>0.050478</td>\n",
       "      <td>1277.799995</td>\n",
       "      <td>106.483334</td>\n",
       "      <td>69.286409</td>\n",
       "      <td>31.682962</td>\n",
       "      <td>1.886310</td>\n",
       "      <td>POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>86.961870</td>\n",
       "      <td>1.009594e+06</td>\n",
       "      <td>0.549495</td>\n",
       "      <td>2.091021</td>\n",
       "      <td>1.815498e+05</td>\n",
       "      <td>0.937940</td>\n",
       "      <td>1.107011</td>\n",
       "      <td>115129.151292</td>\n",
       "      <td>0.983928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.377780</td>\n",
       "      <td>100.031481</td>\n",
       "      <td>57.573416</td>\n",
       "      <td>31.360556</td>\n",
       "      <td>2.301283</td>\n",
       "      <td>POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...</td>\n",
       "      <td>11.249059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.372213</td>\n",
       "      <td>87.021730</td>\n",
       "      <td>24.427693</td>\n",
       "      <td>1072.674988</td>\n",
       "      <td>89.389585</td>\n",
       "      <td>52.837522</td>\n",
       "      <td>31.968540</td>\n",
       "      <td>2.091782</td>\n",
       "      <td>POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...</td>\n",
       "      <td>1.500561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v001    prop_10       edge_10   frac_10    prop_30       edge_30   frac_30  \\\n",
       "0   1.0  97.287300  1.642417e+05  0.866345   1.356350  9.321825e+04  0.964427   \n",
       "1   2.0  13.546798  8.911330e+05  0.790827  79.926108  1.325616e+06  0.484783   \n",
       "2   3.0  13.147410  9.274900e+05  0.852884  72.509960  1.950598e+06  0.383876   \n",
       "3   4.0  86.961870  1.009594e+06  0.549495   2.091021  1.815498e+05  0.937940   \n",
       "4   5.0   0.000000  0.000000e+00  0.000000   0.000000  0.000000e+00  0.000000   \n",
       "\n",
       "    prop_50        edge_50   frac_50  ...  RdLen_LI3  RdLen_LI4  RdLen_LI5  \\\n",
       "0  0.246609   22194.821208  0.989369  ...   2.415456   0.835918   0.099597   \n",
       "1  0.492611   44334.975369  0.979785  ...   0.000000   0.000000   0.000000   \n",
       "2  0.000000       0.000000  0.000000  ...   0.564346   0.364398   0.050478   \n",
       "3  1.107011  115129.151292  0.983928  ...   0.000000   0.000000   0.000000   \n",
       "4  0.000000       0.000000  0.000000  ...  37.372213  87.021730  24.427693   \n",
       "\n",
       "      ac_ppt16    mn_ppt16  std_ppt16  mn_tmax16  std_tmx16  \\\n",
       "0  1617.433322  134.786111  65.901251  30.992685   1.791916   \n",
       "1  1160.712479   96.726042  61.874496  31.332812   1.739660   \n",
       "2  1277.799995  106.483334  69.286409  31.682962   1.886310   \n",
       "3  1200.377780  100.031481  57.573416  31.360556   2.301283   \n",
       "4  1072.674988   89.389585  52.837522  31.968540   2.091782   \n",
       "\n",
       "                                            geometry  rdTt_BtHa  \n",
       "0  POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...   8.992356  \n",
       "1  POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...  12.063733  \n",
       "2  POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...        NaN  \n",
       "3  POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...  11.249059  \n",
       "4  POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...   1.500561  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate road length (km) per built-up pixels (ha):\n",
    "\n",
    "# Total length / built-up pixel count\n",
    "shp_poly_gdf[\"rdTt_BtHa\"] = \"\"\n",
    "shp_poly_gdf[\"rdTt_BtHa\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    shp_poly_gdf[\"RdLenTot\"] / shp_poly_gdf[\"built_pix\"]\n",
    ")\n",
    "\n",
    "# Note: pixels with no built up areas will have blank \"rdTt_BtHa\" (to avoid division by 0)\n",
    "# Replace blanks by NaNs:\n",
    "shp_poly_gdf[\"rdTt_BtHa\"] = shp_poly_gdf.rdTt_BtHa.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "\n",
    "shp_poly_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-9804531af8c7>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"rd_pc_LI\"][shp_poly_gdf['RdLenTot']>0] = (shp_poly_gdf['rd_len_LI']/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v001</th>\n",
       "      <th>prop_10</th>\n",
       "      <th>edge_10</th>\n",
       "      <th>frac_10</th>\n",
       "      <th>prop_30</th>\n",
       "      <th>edge_30</th>\n",
       "      <th>frac_30</th>\n",
       "      <th>prop_50</th>\n",
       "      <th>edge_50</th>\n",
       "      <th>frac_50</th>\n",
       "      <th>...</th>\n",
       "      <th>RdLen_LI5</th>\n",
       "      <th>ac_ppt16</th>\n",
       "      <th>mn_ppt16</th>\n",
       "      <th>std_ppt16</th>\n",
       "      <th>mn_tmax16</th>\n",
       "      <th>std_tmx16</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rdTt_BtHa</th>\n",
       "      <th>rd_len_LI</th>\n",
       "      <th>rd_pc_LI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>97.287300</td>\n",
       "      <td>1.642417e+05</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>1.356350</td>\n",
       "      <td>9.321825e+04</td>\n",
       "      <td>0.964427</td>\n",
       "      <td>0.246609</td>\n",
       "      <td>22194.821208</td>\n",
       "      <td>0.989369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>1617.433322</td>\n",
       "      <td>134.786111</td>\n",
       "      <td>65.901251</td>\n",
       "      <td>30.992685</td>\n",
       "      <td>1.791916</td>\n",
       "      <td>POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...</td>\n",
       "      <td>8.992356</td>\n",
       "      <td>0.935515</td>\n",
       "      <td>0.011559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.546798</td>\n",
       "      <td>8.911330e+05</td>\n",
       "      <td>0.790827</td>\n",
       "      <td>79.926108</td>\n",
       "      <td>1.325616e+06</td>\n",
       "      <td>0.484783</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>44334.975369</td>\n",
       "      <td>0.979785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1160.712479</td>\n",
       "      <td>96.726042</td>\n",
       "      <td>61.874496</td>\n",
       "      <td>31.332812</td>\n",
       "      <td>1.739660</td>\n",
       "      <td>POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...</td>\n",
       "      <td>12.063733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.147410</td>\n",
       "      <td>9.274900e+05</td>\n",
       "      <td>0.852884</td>\n",
       "      <td>72.509960</td>\n",
       "      <td>1.950598e+06</td>\n",
       "      <td>0.383876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050478</td>\n",
       "      <td>1277.799995</td>\n",
       "      <td>106.483334</td>\n",
       "      <td>69.286409</td>\n",
       "      <td>31.682962</td>\n",
       "      <td>1.886310</td>\n",
       "      <td>POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414876</td>\n",
       "      <td>0.009099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>86.961870</td>\n",
       "      <td>1.009594e+06</td>\n",
       "      <td>0.549495</td>\n",
       "      <td>2.091021</td>\n",
       "      <td>1.815498e+05</td>\n",
       "      <td>0.937940</td>\n",
       "      <td>1.107011</td>\n",
       "      <td>115129.151292</td>\n",
       "      <td>0.983928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.377780</td>\n",
       "      <td>100.031481</td>\n",
       "      <td>57.573416</td>\n",
       "      <td>31.360556</td>\n",
       "      <td>2.301283</td>\n",
       "      <td>POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...</td>\n",
       "      <td>11.249059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.427693</td>\n",
       "      <td>1072.674988</td>\n",
       "      <td>89.389585</td>\n",
       "      <td>52.837522</td>\n",
       "      <td>31.968540</td>\n",
       "      <td>2.091782</td>\n",
       "      <td>POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...</td>\n",
       "      <td>1.500561</td>\n",
       "      <td>111.449423</td>\n",
       "      <td>0.589459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v001    prop_10       edge_10   frac_10    prop_30       edge_30   frac_30  \\\n",
       "0   1.0  97.287300  1.642417e+05  0.866345   1.356350  9.321825e+04  0.964427   \n",
       "1   2.0  13.546798  8.911330e+05  0.790827  79.926108  1.325616e+06  0.484783   \n",
       "2   3.0  13.147410  9.274900e+05  0.852884  72.509960  1.950598e+06  0.383876   \n",
       "3   4.0  86.961870  1.009594e+06  0.549495   2.091021  1.815498e+05  0.937940   \n",
       "4   5.0   0.000000  0.000000e+00  0.000000   0.000000  0.000000e+00  0.000000   \n",
       "\n",
       "    prop_50        edge_50   frac_50  ...  RdLen_LI5     ac_ppt16    mn_ppt16  \\\n",
       "0  0.246609   22194.821208  0.989369  ...   0.099597  1617.433322  134.786111   \n",
       "1  0.492611   44334.975369  0.979785  ...   0.000000  1160.712479   96.726042   \n",
       "2  0.000000       0.000000  0.000000  ...   0.050478  1277.799995  106.483334   \n",
       "3  1.107011  115129.151292  0.983928  ...   0.000000  1200.377780  100.031481   \n",
       "4  0.000000       0.000000  0.000000  ...  24.427693  1072.674988   89.389585   \n",
       "\n",
       "   std_ppt16  mn_tmax16  std_tmx16  \\\n",
       "0  65.901251  30.992685   1.791916   \n",
       "1  61.874496  31.332812   1.739660   \n",
       "2  69.286409  31.682962   1.886310   \n",
       "3  57.573416  31.360556   2.301283   \n",
       "4  52.837522  31.968540   2.091782   \n",
       "\n",
       "                                            geometry  rdTt_BtHa   rd_len_LI  \\\n",
       "0  POLYGON ((-3.15356 5.97345, -3.15377 5.96907, ...   8.992356    0.935515   \n",
       "1  POLYGON ((-8.16706 6.46250, -8.16728 6.45813, ...  12.063733    0.000000   \n",
       "2  POLYGON ((-8.27965 7.27460, -8.27986 7.27023, ...        NaN    0.414876   \n",
       "3  POLYGON ((-3.01465 7.73145, -3.01486 7.72709, ...  11.249059    0.000000   \n",
       "4  POLYGON ((-5.02274 7.71383, -5.02283 7.71208, ...   1.500561  111.449423   \n",
       "\n",
       "   rd_pc_LI  \n",
       "0  0.011559  \n",
       "1       0.0  \n",
       "2  0.009099  \n",
       "3       0.0  \n",
       "4  0.589459  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEARITY of roads\n",
    "\n",
    "# Calculate length of linear roads (classes 4 & 5, defined based on cartographic results)\n",
    "shp_poly_gdf[\"rd_len_LI\"] = \"\"\n",
    "shp_poly_gdf[\"rd_len_LI\"] = shp_poly_gdf[\"RdLen_LI4\"] + shp_poly_gdf[\"RdLen_LI5\"]\n",
    "\n",
    "# Calculate proportion of linear roads (classes 4 & 5):\n",
    "# Length classes 4 & 5 / total length\n",
    "shp_poly_gdf[\"rd_pc_LI\"] = \"\"\n",
    "shp_poly_gdf[\"rd_pc_LI\"][shp_poly_gdf[\"RdLenTot\"] > 0] = (\n",
    "    shp_poly_gdf[\"rd_len_LI\"] / shp_poly_gdf[\"RdLenTot\"]\n",
    ")\n",
    "\n",
    "# Note: pixels with no roads will have blank \"rd_pc_LI\" (to avoid division by 0)\n",
    "# Replace blanks by NaNs:\n",
    "shp_poly_gdf[\"rd_pc_LI\"] = shp_poly_gdf.rd_pc_LI.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "\n",
    "shp_poly_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of units w/ at least 1 high-density pixel:  155\n",
      "number of units w/ at least 1 very-high density pixel:  46\n",
      "number of units w/ at least 1 precarious area pixel (type I):  192\n",
      "number of units w/ at least 1 precarious area pixel (type II):  192\n",
      "number of units w/ at least 1 VERY precarious area pixel:  25\n",
      "number of units w/ at least 1 well-illuminated area area pixel:  157\n",
      "number of units w/ at least 1 well-illuminated area area pixel:  97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-7a7109786db1>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_HiDen\"][shp_poly_gdf[\"built_pix\"]>0] = ((shp_poly_gdf[\"prop_19031\"]+\n",
      "<ipython-input-28-7a7109786db1>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_HiDen\"][shp_poly_gdf[\"built_pix\"]==0] = np.nan\n",
      "<ipython-input-28-7a7109786db1>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_VHden\"][shp_poly_gdf[\"built_pix\"]>0] = ((#shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
      "<ipython-input-28-7a7109786db1>:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_VHden\"][shp_poly_gdf[\"built_pix\"]==0] = np.nan\n",
      "<ipython-input-28-7a7109786db1>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"prop_Prec\"][shp_poly_gdf[\"built_pix\"]>0] = (shp_poly_gdf[\"prop_1\"]/shp_poly_gdf[\"prop_190\"])*100\n",
      "<ipython-input-28-7a7109786db1>:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"prop_Prec\"][shp_poly_gdf[\"built_pix\"]==0] = np.nan\n",
      "<ipython-input-28-7a7109786db1>:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_PrecAr\"][shp_poly_gdf[\"built_pix\"]>0] = ((shp_poly_gdf[\"prop_19021\"]+\n",
      "<ipython-input-28-7a7109786db1>:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_PrecAr\"][shp_poly_gdf[\"built_pix\"]==0] = np.nan\n",
      "<ipython-input-28-7a7109786db1>:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_VPrcAr\"][shp_poly_gdf[\"built_pix\"]>0] = ((shp_poly_gdf[\"prop_19031\"]+\n",
      "<ipython-input-28-7a7109786db1>:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_VPrcAr\"][shp_poly_gdf[\"built_pix\"]==0] = np.nan\n",
      "<ipython-input-28-7a7109786db1>:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_WelIll\"][shp_poly_gdf[\"built_pix\"]>0] = ((shp_poly_gdf[\"prop_19013\"]+\n",
      "<ipython-input-28-7a7109786db1>:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_WelIll\"][shp_poly_gdf[\"built_pix\"]==0] = np.nan\n",
      "<ipython-input-28-7a7109786db1>:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_VWelIl\"][shp_poly_gdf[\"built_pix\"]>0] = ((shp_poly_gdf[\"prop_19014\"]+\n",
      "<ipython-input-28-7a7109786db1>:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shp_poly_gdf[\"pc_VWelIl\"][shp_poly_gdf[\"built_pix\"]==0] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# Calculate independent variables derived from land cover classes\n",
    "\n",
    "# Percentage of high-density pixels (dense built up pixels (last decile) / total built-up pixels)\n",
    "shp_poly_gdf[\"pc_HiDen\"] = \"\"\n",
    "shp_poly_gdf[\"pc_HiDen\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    (\n",
    "        shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    "    / (\n",
    "        shp_poly_gdf[\"prop_19011\"]\n",
    "        + shp_poly_gdf[\"prop_19012\"]\n",
    "        + shp_poly_gdf[\"prop_19013\"]\n",
    "        + shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19021\"]\n",
    "        + shp_poly_gdf[\"prop_19022\"]\n",
    "        + shp_poly_gdf[\"prop_19023\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "# Note: pixels with no built-up areas will have errors (division by 0)\n",
    "# Replace by NaNs\n",
    "shp_poly_gdf[\"pc_HiDen\"][shp_poly_gdf[\"built_pix\"] == 0] = np.nan\n",
    "\n",
    "print(\n",
    "    \"number of units w/ at least 1 high-density pixel: \",\n",
    "    np.asarray(shp_poly_gdf[shp_poly_gdf.pc_HiDen > 0]).shape[0],\n",
    ")\n",
    "\n",
    "# Percentage of very high-density pixels (dense built up pixels (last decile) / total built-up pixels)\n",
    "shp_poly_gdf[\"pc_VHden\"] = \"\"\n",
    "shp_poly_gdf[\"pc_VHden\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    (  # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    "    / (\n",
    "        shp_poly_gdf[\"prop_19011\"]\n",
    "        + shp_poly_gdf[\"prop_19012\"]\n",
    "        + shp_poly_gdf[\"prop_19013\"]\n",
    "        + shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19021\"]\n",
    "        + shp_poly_gdf[\"prop_19022\"]\n",
    "        + shp_poly_gdf[\"prop_19023\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "# Note: pixels with no built-up areas will have errors (division by 0)\n",
    "# Replace by NaNs\n",
    "shp_poly_gdf[\"pc_VHden\"][shp_poly_gdf[\"built_pix\"] == 0] = np.nan\n",
    "\n",
    "print(\n",
    "    \"number of units w/ at least 1 very-high density pixel: \",\n",
    "    np.asarray(shp_poly_gdf[shp_poly_gdf.pc_VHden > 0]).shape[0],\n",
    ")\n",
    "\n",
    "\n",
    "# Percentage of precarious areas I ('prop_1' / 'prop_190')\n",
    "shp_poly_gdf[\"prop_Prec\"] = \"\"\n",
    "shp_poly_gdf[\"prop_Prec\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    shp_poly_gdf[\"prop_1\"] / shp_poly_gdf[\"prop_190\"]\n",
    ") * 100\n",
    "\n",
    "# Replace by NaNs\n",
    "shp_poly_gdf[\"prop_Prec\"][shp_poly_gdf[\"built_pix\"] == 0] = np.nan\n",
    "\n",
    "print(\n",
    "    \"number of units w/ at least 1 precarious area pixel (type I): \",\n",
    "    np.asarray(shp_poly_gdf[shp_poly_gdf.prop_Prec > 0]).shape[0],\n",
    ")\n",
    "\n",
    "\n",
    "# Percentage of precarious areas II (n pixels[density factor > light factor] / total n buit-up pixels)\n",
    "shp_poly_gdf[\"pc_PrecAr\"] = \"\"\n",
    "shp_poly_gdf[\"pc_PrecAr\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    (\n",
    "        shp_poly_gdf[\"prop_19021\"]\n",
    "        + shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "    )\n",
    "    / (\n",
    "        shp_poly_gdf[\"prop_19011\"]\n",
    "        + shp_poly_gdf[\"prop_19012\"]\n",
    "        + shp_poly_gdf[\"prop_19013\"]\n",
    "        + shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19021\"]\n",
    "        + shp_poly_gdf[\"prop_19022\"]\n",
    "        + shp_poly_gdf[\"prop_19023\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "# Note: pixels with no built-up areas will have errors (division by 0)\n",
    "# Replace by NaNs\n",
    "shp_poly_gdf[\"pc_PrecAr\"][shp_poly_gdf[\"built_pix\"] == 0] = np.nan\n",
    "\n",
    "print(\n",
    "    \"number of units w/ at least 1 precarious area pixel (type II): \",\n",
    "    np.asarray(shp_poly_gdf[shp_poly_gdf.pc_PrecAr > 0]).shape[0],\n",
    ")\n",
    "\n",
    "# Percentage of VERY precarious areas (n pixels[density factor >> light factor] / total n buit-up pixels)\n",
    "shp_poly_gdf[\"pc_VPrcAr\"] = \"\"\n",
    "shp_poly_gdf[\"pc_VPrcAr\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    (\n",
    "        shp_poly_gdf[\"prop_19031\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "    )\n",
    "    / (\n",
    "        shp_poly_gdf[\"prop_19011\"]\n",
    "        + shp_poly_gdf[\"prop_19012\"]\n",
    "        + shp_poly_gdf[\"prop_19013\"]\n",
    "        + shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19021\"]\n",
    "        + shp_poly_gdf[\"prop_19022\"]\n",
    "        + shp_poly_gdf[\"prop_19023\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "# Note: pixels with no built-up areas will have errors (division by 0)\n",
    "# Replace by NaNs\n",
    "shp_poly_gdf[\"pc_VPrcAr\"][shp_poly_gdf[\"built_pix\"] == 0] = np.nan\n",
    "\n",
    "print(\n",
    "    \"number of units w/ at least 1 VERY precarious area pixel: \",\n",
    "    np.asarray(shp_poly_gdf[shp_poly_gdf.pc_VPrcAr > 0]).shape[0],\n",
    ")\n",
    "\n",
    "# Percentage of WELL ILLUMINATED areas (pixels with illum. group > 2 / total pixels)\n",
    "shp_poly_gdf[\"pc_WelIll\"] = \"\"\n",
    "shp_poly_gdf[\"pc_WelIll\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    (\n",
    "        shp_poly_gdf[\"prop_19013\"]\n",
    "        + shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19023\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    "    / (\n",
    "        shp_poly_gdf[\"prop_19011\"]\n",
    "        + shp_poly_gdf[\"prop_19012\"]\n",
    "        + shp_poly_gdf[\"prop_19013\"]\n",
    "        + shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19021\"]\n",
    "        + shp_poly_gdf[\"prop_19022\"]\n",
    "        + shp_poly_gdf[\"prop_19023\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "# Note: pixels with no built-up areas will have errors (division by 0)\n",
    "# Replace by NaNs\n",
    "shp_poly_gdf[\"pc_WelIll\"][shp_poly_gdf[\"built_pix\"] == 0] = np.nan\n",
    "\n",
    "print(\n",
    "    \"number of units w/ at least 1 well-illuminated area area pixel: \",\n",
    "    np.asarray(shp_poly_gdf[shp_poly_gdf.pc_WelIll > 0]).shape[0],\n",
    ")\n",
    "\n",
    "# Percentage of VERY WELL ILLUMINATED areas (pixels with illum. group > 3 / total pixels)\n",
    "shp_poly_gdf[\"pc_VWelIl\"] = \"\"\n",
    "shp_poly_gdf[\"pc_VWelIl\"][shp_poly_gdf[\"built_pix\"] > 0] = (\n",
    "    (\n",
    "        shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    "    / (\n",
    "        shp_poly_gdf[\"prop_19011\"]\n",
    "        + shp_poly_gdf[\"prop_19012\"]\n",
    "        + shp_poly_gdf[\"prop_19013\"]\n",
    "        + shp_poly_gdf[\"prop_19014\"]\n",
    "        + shp_poly_gdf[\"prop_19021\"]\n",
    "        + shp_poly_gdf[\"prop_19022\"]\n",
    "        + shp_poly_gdf[\"prop_19023\"]\n",
    "        + shp_poly_gdf[\"prop_19024\"]\n",
    "        + shp_poly_gdf[\"prop_19031\"]\n",
    "        + shp_poly_gdf[\"prop_19032\"]\n",
    "        + shp_poly_gdf[\"prop_19033\"]\n",
    "        + shp_poly_gdf[\"prop_19034\"]\n",
    "        +\n",
    "        # shp_poly_gdf[\"prop_19041\"]+ # class does not exist\n",
    "        shp_poly_gdf[\"prop_19042\"]\n",
    "        + shp_poly_gdf[\"prop_19043\"]\n",
    "        + shp_poly_gdf[\"prop_19044\"]\n",
    "    )\n",
    ") * 100\n",
    "\n",
    "# Note: pixels with no built-up areas will have errors (division by 0)\n",
    "# Replace by NaNs\n",
    "shp_poly_gdf[\"pc_VWelIl\"][shp_poly_gdf[\"built_pix\"] == 0] = np.nan\n",
    "\n",
    "print(\n",
    "    \"number of units w/ at least 1 well-illuminated area area pixel: \",\n",
    "    np.asarray(shp_poly_gdf[shp_poly_gdf.pc_VWelIl > 0]).shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final gdf saved\n"
     ]
    }
   ],
   "source": [
    "# Save file\n",
    "shp_poly_gdf.to_file(path.join(dest_dir, \"AGGR_DHS_buffer_4stats.shp\"))\n",
    "print(\"final gdf saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LS_Metrics",
   "language": "python",
   "name": "ls_metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
